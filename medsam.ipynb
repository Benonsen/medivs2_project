{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fdfab4-ad43-4e4b-a3f4-0b60f83a90d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from transformers import SamModel, SamProcessor\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "class SAMUltrasoundDataset(Dataset):\n",
    "    def __init__(self, csv_file, base_path, split=\"train\", image_size=256):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.data = self.data[self.data[\"Split\"].str.lower() == split.lower()]\n",
    "        self.base_path = base_path\n",
    "        self.image_size = image_size\n",
    "        \n",
    "        self.image_transform = T.Compose([\n",
    "            T.Resize((image_size, image_size)),\n",
    "            T.ToTensor()\n",
    "        ])\n",
    "        self.mask_transform = T.Compose([\n",
    "            T.Resize((image_size, image_size)), \n",
    "            T.ToTensor()\n",
    "        ])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        filename = row[\"FileName\"].strip() + \".png\"\n",
    "        image_path = os.path.join(self.base_path, filename.lstrip(\"/\"))\n",
    "        mask_path = image_path.replace(\"/frames/\", \"/mask/\")\n",
    "        \n",
    "        # Load images\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        mask = Image.open(mask_path).convert(\"L\") \n",
    "        \n",
    "        orig_w, orig_h = image.size\n",
    "        \n",
    "        image_tensor = self.image_transform(image)\n",
    "        mask_tensor = self.mask_transform(mask)\n",
    "        mask_tensor = (mask_tensor > 0.5).float()\n",
    "        \n",
    "        # scale\n",
    "        scaled_x = int(row[\"x\"] * self.image_size / orig_w)\n",
    "        scaled_y = int(row[\"y\"] * self.image_size / orig_h)\n",
    "        \n",
    "        return {\n",
    "            \"image\": image_tensor,\n",
    "            \"mask\": mask_tensor,\n",
    "            \"point_coords\": [[scaled_x, scaled_y]],\n",
    "            \"image_path\": image_path\n",
    "        }\n",
    "\n",
    "def sam_collator(batch):\n",
    "    images = [b[\"image\"] for b in batch]\n",
    "    masks = torch.stack([b[\"mask\"] for b in batch])\n",
    "    \n",
    "    if len(masks.shape) == 3:\n",
    "        masks = masks.unsqueeze(1) \n",
    "    \n",
    "    coords = [b[\"point_coords\"] for b in batch]\n",
    "    \n",
    "    return {\n",
    "        \"images\": images,\n",
    "        \"masks\": masks,\n",
    "        \"point_coords\": coords\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77e6b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, processor, dataloader, optimizer, device, epoch, gradient_accumulation_steps=1):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    num_batches = len(dataloader)\n",
    "    \n",
    "    progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch}\")\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    for batch_idx, batch in enumerate(progress_bar):\n",
    "        try:\n",
    "            images = batch[\"images\"]\n",
    "            masks = batch[\"masks\"].to(device)\n",
    "            point_coords = batch[\"point_coords\"]\n",
    "            \n",
    "            images_np = [img.permute(1, 2, 0).cpu().numpy() for img in images]\n",
    "            \n",
    "            inputs = processor(\n",
    "                images=images_np,\n",
    "                input_points=point_coords,\n",
    "                return_tensors=\"pt\",\n",
    "                do_rescale=False,\n",
    "                padding=\"longest\"\n",
    "            ).to(device)\n",
    "            \n",
    "            outputs = model(**inputs, multimask_output=False)\n",
    "            pred_masks = outputs.pred_masks.squeeze(1)\n",
    "            \n",
    "            if masks.shape != pred_masks.shape:\n",
    "                masks = torch.nn.functional.interpolate(\n",
    "                    masks.float(), \n",
    "                    size=pred_masks.shape[-2:], \n",
    "                    mode='nearest'\n",
    "                )\n",
    "            \n",
    "            loss = nn.functional.binary_cross_entropy_with_logits(pred_masks, masks)\n",
    "            loss = loss / gradient_accumulation_steps \n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            if (batch_idx + 1) % gradient_accumulation_steps == 0:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "            \n",
    "            total_loss += loss.item() * gradient_accumulation_steps\n",
    "            \n",
    "            progress_bar.set_postfix({\n",
    "                'loss': f'{loss.item() * gradient_accumulation_steps:.4f}',\n",
    "                'avg_loss': f'{total_loss / (batch_idx + 1):.4f}'\n",
    "            })\n",
    "            \n",
    "        except torch.cuda.OutOfMemoryError:\n",
    "            print(f\"CUDA OOM error at batch {batch_idx}. Skipping batch...\")\n",
    "            torch.cuda.empty_cache()\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing batch {batch_idx}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # handle remaining gradient\n",
    "    if (batch_idx + 1) % gradient_accumulation_steps != 0:\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    avg_loss = total_loss / num_batches\n",
    "    return avg_loss\n",
    "\n",
    "def validate_epoch(model, processor, dataloader, device, epoch):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    num_batches = len(dataloader)\n",
    "    \n",
    "    progress_bar = tqdm(dataloader, desc=f\"Validation {epoch}\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(progress_bar):\n",
    "            try:\n",
    "                images = batch[\"images\"]\n",
    "                masks = batch[\"masks\"].to(device)\n",
    "                point_coords = batch[\"point_coords\"]\n",
    "                \n",
    "                images_np = [img.permute(1, 2, 0).cpu().numpy() for img in images]\n",
    "                \n",
    "                inputs = processor(\n",
    "                    images=images_np,\n",
    "                    input_points=point_coords,\n",
    "                    return_tensors=\"pt\",\n",
    "                    do_rescale=False,\n",
    "                    padding=\"longest\"\n",
    "                ).to(device)\n",
    "                \n",
    "                outputs = model(**inputs, multimask_output=False)\n",
    "                pred_masks = outputs.pred_masks.squeeze(1)\n",
    "                \n",
    "                if masks.shape != pred_masks.shape:\n",
    "                    masks = torch.nn.functional.interpolate(\n",
    "                        masks.float(), \n",
    "                        size=pred_masks.shape[-2:], \n",
    "                        mode='nearest'\n",
    "                    )\n",
    "                \n",
    "                loss = nn.functional.binary_cross_entropy_with_logits(pred_masks, masks)\n",
    "                total_loss += loss.item()\n",
    "                \n",
    "                progress_bar.set_postfix({\n",
    "                    'val_loss': f'{loss.item():.4f}',\n",
    "                    'avg_val_loss': f'{total_loss / (batch_idx + 1):.4f}'\n",
    "                })\n",
    "                \n",
    "            except torch.cuda.OutOfMemoryError:\n",
    "                print(f\"CUDA OOM error at validation batch {batch_idx}. Skipping batch...\")\n",
    "                torch.cuda.empty_cache()\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing validation batch {batch_idx}: {e}\")\n",
    "                continue\n",
    "    \n",
    "    avg_loss = total_loss / num_batches\n",
    "    return avg_loss\n",
    "\n",
    "def save_checkpoint(model, optimizer, epoch, loss, filepath):\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss,\n",
    "    }\n",
    "    torch.save(checkpoint, filepath)\n",
    "    print(f\"Checkpoint saved to {filepath}\")\n",
    "\n",
    "def load_checkpoint(model, optimizer, filepath, device):\n",
    "    checkpoint = torch.load(filepath, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    print(f\"Checkpoint loaded from {filepath}, epoch {epoch}, loss {loss:.4f}\")\n",
    "    return epoch, loss\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2e738f",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"medivs2_project/filelist_frames_dataset.csv\"\n",
    "base_path = \"/home/jovyan/.cache/kagglehub/datasets/foghorn/echonet-frames-masks-dataset/versions/1/Echonet-Frames-Masks-Dataset/\"\n",
    "image_size = 1024\n",
    "\n",
    "num_epochs = 3\n",
    "batch_size = 1\n",
    "gradient_accumulation_steps = 16\n",
    "learning_rate = 1e-5\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "model = SamModel.from_pretrained(\"wanglab/medsam-vit-base\").to(device)\n",
    "processor = SamProcessor.from_pretrained(\"wanglab/medsam-vit-base\")\n",
    "\n",
    "train_dataset = SAMUltrasoundDataset(csv_path, base_path, split=\"TRAIN\", image_size=image_size)\n",
    "val_dataset = SAMUltrasoundDataset(csv_path, base_path, split=\"VAL\", image_size=image_size)\n",
    "test_dataset = SAMUltrasoundDataset(csv_path, base_path, split=\"TEST\", image_size=image_sizef)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True, \n",
    "    collate_fn=sam_collator,\n",
    "    num_workers=0,\n",
    "    pin_memory=False\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False, \n",
    "    collate_fn=sam_collator,\n",
    "    num_workers=0,\n",
    "    pin_memory=False\n",
    ")\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
    "\n",
    "checkpoint_dir = \"./sam_ultrasound_checkpoints\"\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU memory allocated: {torch.cuda.memory_allocated()/1024**3:.2f} GB\")\n",
    "    print(f\"GPU memory cached: {torch.cuda.memory_reserved()/1024**3:.2f} GB\")\n",
    "\n",
    "print(f\"Training dataset size: {len(train_dataset)}\")\n",
    "print(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "print(f\"Training batches: {len(train_loader)}\")\n",
    "print(f\"Validation batches: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05f8cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_loss = float('inf')\n",
    "    \n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\n=== Epoch {epoch + 1}/{num_epochs} ===\")\n",
    "    \n",
    "    train_loss = train_epoch(\n",
    "        model, processor, train_loader, optimizer, device, \n",
    "        epoch + 1, gradient_accumulation_steps\n",
    "    )\n",
    "    \n",
    "    val_loss = validate_epoch(model, processor, val_loader, device, epoch + 1)\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1} - Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "    \n",
    "    checkpoint_path = os.path.join(checkpoint_dir, f\"checkpoint_epoch_{epoch + 1}.pt\")\n",
    "    save_checkpoint(model, optimizer, epoch + 1, val_loss, checkpoint_path)\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_checkpoint_path = os.path.join(checkpoint_dir, \"best_model.pt\")\n",
    "        save_checkpoint(model, optimizer, epoch + 1, val_loss, best_checkpoint_path)\n",
    "        print(f\"New best model saved with validation loss: {val_loss:.4f}\")\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "print(\"Training completed!\")\n",
    "print(f\"Best validation loss: {best_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e201e61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import zoom\n",
    "\n",
    "\n",
    "\n",
    "def run_sam_inference(dataset, model, processor, device, num_examples=3, batch_size=1):\n",
    "    model.eval()\n",
    "    \n",
    "    for i in range(0, num_examples, batch_size):\n",
    "        end_idx = min(i + batch_size, num_examples)\n",
    "        batch_indices = range(i, end_idx)\n",
    "        \n",
    "        batch_images = []\n",
    "        batch_coords = []\n",
    "        batch_samples = []\n",
    "        \n",
    "        for idx in batch_indices:\n",
    "            sample = dataset[idx]\n",
    "            batch_images.append(sample[\"image\"])\n",
    "            batch_coords.append(sample[\"point_coords\"])\n",
    "            batch_samples.append(sample)\n",
    "        \n",
    "        try:\n",
    "            inputs = processor(\n",
    "                images=batch_images,\n",
    "                input_points=batch_coords,\n",
    "                return_tensors=\"pt\",\n",
    "                do_rescale=False,\n",
    "                padding=\"longest\"\n",
    "            ).to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = model(**inputs)\n",
    "            \n",
    "            pred_masks = outputs.pred_masks.cpu()\n",
    "            \n",
    "            for j, (sample, pred_mask) in enumerate(zip(batch_samples, pred_masks)):\n",
    "                actual_idx = i + j\n",
    "                print(f\"\\n--- Sample {actual_idx + 1} ---\")\n",
    "                print(f\"Image shape: {sample['image'].shape}\")\n",
    "                print(f\"Point coordinates: {sample['point_coords']}\")\n",
    "                print(f\"Raw predicted mask shape: {pred_mask.shape}\")\n",
    "                \n",
    "                show_mask_and_image(\n",
    "                    image_tensor=sample[\"image\"],\n",
    "                    pred_mask=pred_mask.squeeze(),\n",
    "                    true_mask=sample[\"mask\"].squeeze(),\n",
    "                    title=sample[\"image_path\"],\n",
    "                    coords=sample[\"point_coords\"]\n",
    "                )\n",
    "                \n",
    "        except torch.cuda.OutOfMemoryError:\n",
    "            print(f\"CUDA OOM error with batch size {batch_size}. Try reducing batch_size.\")\n",
    "            torch.cuda.empty_cache()\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing batch: {e}\")\n",
    "            continue\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "def show_mask_and_image(image_tensor, pred_mask, true_mask, title, coords):\n",
    "    image = image_tensor.permute(1, 2, 0).numpy()\n",
    "    image_h, image_w = image.shape[:2]\n",
    "    \n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # input image\n",
    "    plt.subplot(1, 4, 1)\n",
    "    plt.imshow(image)\n",
    "    plt.scatter(coords[0][0], coords[0][1], c='red', s=50, marker='*')\n",
    "    plt.title(\"Original Image + Point\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 4, 2)\n",
    "    medsam_seg_prob = torch.sigmoid(pred_mask).numpy()\n",
    "    \n",
    "    if len(medsam_seg_prob.shape) == 3:\n",
    "        mask_2d = medsam_seg_prob[0]\n",
    "    else:\n",
    "        mask_2d = medsam_seg_prob\n",
    "    \n",
    "    binary_mask = (mask_2d > 0.5).astype(np.float32)\n",
    "    \n",
    "    if binary_mask.shape != (image_h, image_w):\n",
    "        scale_y = image_h / binary_mask.shape[0]\n",
    "        scale_x = image_w / binary_mask.shape[1]\n",
    "        binary_mask = zoom(binary_mask, (scale_y, scale_x), order=0)  # nearest neighbor\n",
    "    \n",
    "    plt.imshow(binary_mask, cmap=\"gray\")\n",
    "    plt.title(f\"Predicted Mask (Binary)\\nShape: {binary_mask.shape}\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 4, 3)\n",
    "    true_mask_np = true_mask.numpy()\n",
    "    if len(true_mask_np.shape) == 3:\n",
    "        true_mask_np = true_mask_np[0]\n",
    "    \n",
    "    true_binary = (true_mask_np > 0.5).astype(np.float32)\n",
    "    \n",
    "    if true_binary.shape != (image_h, image_w):\n",
    "        scale_y = image_h / true_binary.shape[0]\n",
    "        scale_x = image_w / true_binary.shape[1]\n",
    "        true_binary = zoom(true_binary, (scale_y, scale_x), order=0)\n",
    "    \n",
    "    plt.imshow(true_binary, cmap=\"gray\")\n",
    "    plt.title(f\"Ground Truth Mask (Binary)\\nShape: {true_binary.shape}\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 4, 4)\n",
    "    plt.imshow(image)\n",
    "    colored_mask = np.zeros((*binary_mask.shape, 4))  # RGBA\n",
    "    colored_mask[binary_mask > 0.5] = [1, 0, 0, 0.6]  # Red with alpha\n",
    "    plt.imshow(colored_mask)\n",
    "    plt.scatter(coords[0][0], coords[0][1], c='yellow', s=50, marker='*', edgecolors='black')\n",
    "    plt.title(\"Overlay\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    print(f\"Image shape: {image.shape}\")\n",
    "    print(f\"Original pred mask shape: {medsam_seg_prob.shape}\")\n",
    "    print(f\"Final binary mask shape: {binary_mask.shape}\")\n",
    "    print(f\"Mask coverage: {np.sum(binary_mask > 0.5)} pixels\")\n",
    "    \n",
    "    plt.suptitle(os.path.basename(title), fontsize=10)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfeca70-802a-4730-979b-d5eb7e02030b",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_sam_inference(val_dataset, model, processor, device, num_examples=10, batch_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b4fb9e-32bc-4e15-a509-813403297f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import zoom\n",
    "\n",
    "def dice_coefficient(pred_mask, true_mask, smooth=1e-6):\n",
    "    if torch.is_tensor(pred_mask):\n",
    "        pred_mask = pred_mask.cpu().numpy()\n",
    "    if torch.is_tensor(true_mask):\n",
    "        true_mask = true_mask.cpu().numpy()\n",
    "    \n",
    "    pred_binary = (pred_mask > 0.5).astype(np.float32)\n",
    "    true_binary = (true_mask > 0.5).astype(np.float32)\n",
    "    \n",
    "    intersection = np.sum(pred_binary * true_binary)\n",
    "    total = np.sum(pred_binary) + np.sum(true_binary)\n",
    "    \n",
    "    dice_score = (2.0 * intersection + smooth) / (total + smooth)\n",
    "    \n",
    "    return dice_score\n",
    "\n",
    "def iou_coefficient(pred_mask, true_mask, smooth=1e-6):\n",
    "    if torch.is_tensor(pred_mask):\n",
    "        pred_mask = pred_mask.cpu().numpy()\n",
    "    if torch.is_tensor(true_mask):\n",
    "        true_mask = true_mask.cpu().numpy()\n",
    "    \n",
    "    pred_binary = (pred_mask > 0.5).astype(np.float32)\n",
    "    true_binary = (true_mask > 0.5).astype(np.float32)\n",
    "    \n",
    "    intersection = np.sum(pred_binary * true_binary)\n",
    "    union = np.sum(pred_binary) + np.sum(true_binary) - intersection\n",
    "    \n",
    "    iou_score = (intersection + smooth) / (union + smooth)\n",
    "    \n",
    "    return iou_score\n",
    "\n",
    "def precision_recall_f1(pred_mask, true_mask, smooth=1e-6):\n",
    "    if torch.is_tensor(pred_mask):\n",
    "        pred_mask = pred_mask.cpu().numpy()\n",
    "    if torch.is_tensor(true_mask):\n",
    "        true_mask = true_mask.cpu().numpy()\n",
    "    \n",
    "    pred_binary = (pred_mask > 0.5).astype(np.float32)\n",
    "    true_binary = (true_mask > 0.5).astype(np.float32)\n",
    "    \n",
    "    tp = np.sum(pred_binary * true_binary)\n",
    "    fp = np.sum(pred_binary * (1 - true_binary))\n",
    "    fn = np.sum((1 - pred_binary) * true_binary)\n",
    "    \n",
    "    precision = (tp + smooth) / (tp + fp + smooth)\n",
    "    recall = (tp + smooth) / (tp + fn + smooth)\n",
    "    f1_score = (2 * precision * recall + smooth) / (precision + recall + smooth)\n",
    "    \n",
    "    return precision, recall, f1_score\n",
    "\n",
    "def evaluate_sam_model(model, processor, dataset, device, num_samples=None, batch_size=1, \n",
    "                      save_visualizations=False, visualization_dir=\"./eval_visualizations\"):\n",
    "    model.eval()\n",
    "    \n",
    "    if num_samples is None:\n",
    "        num_samples = len(dataset)\n",
    "    else:\n",
    "        num_samples = min(num_samples, len(dataset))\n",
    "    \n",
    "    dice_scores = []\n",
    "    iou_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    f1_scores = []\n",
    "    \n",
    "    if save_visualizations:\n",
    "        import os\n",
    "        os.makedirs(visualization_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"Evaluating model on {num_samples} samples...\")\n",
    "    \n",
    "    for i in range(0, num_samples, batch_size):\n",
    "        end_idx = min(i + batch_size, num_samples)\n",
    "        batch_indices = range(i, end_idx)\n",
    "        \n",
    "        batch_images = []\n",
    "        batch_coords = []\n",
    "        batch_samples = []\n",
    "        \n",
    "        for idx in batch_indices:\n",
    "            sample = dataset[idx]\n",
    "            batch_images.append(sample[\"image\"])\n",
    "            batch_coords.append(sample[\"point_coords\"])\n",
    "            batch_samples.append(sample)\n",
    "        \n",
    "        try:\n",
    "            inputs = processor(\n",
    "                images=batch_images,\n",
    "                input_points=batch_coords,\n",
    "                return_tensors=\"pt\",\n",
    "                do_rescale=False,\n",
    "                padding=\"longest\"\n",
    "            ).to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = model(**inputs)\n",
    "            \n",
    "            pred_masks = outputs.pred_masks.cpu()\n",
    "            \n",
    "            for j, (sample, raw_pred_mask) in enumerate(zip(batch_samples, pred_masks)):\n",
    "                actual_idx = i + j\n",
    "                \n",
    "                pred_mask = torch.sigmoid(raw_pred_mask.squeeze()).numpy()\n",
    "                if len(pred_mask.shape) == 3:\n",
    "                    pred_mask = pred_mask[0]\n",
    "                \n",
    "                true_mask = sample[\"mask\"].squeeze().numpy()\n",
    "                if len(true_mask.shape) == 3:\n",
    "                    true_mask = true_mask[0]\n",
    "                \n",
    "                if pred_mask.shape != true_mask.shape:\n",
    "                    scale_y = true_mask.shape[0] / pred_mask.shape[0]\n",
    "                    scale_x = true_mask.shape[1] / pred_mask.shape[1]\n",
    "                    pred_mask = zoom(pred_mask, (scale_y, scale_x), order=1)  \n",
    "                \n",
    "                dice_score = dice_coefficient(pred_mask, true_mask)\n",
    "                iou_score = iou_coefficient(pred_mask, true_mask)\n",
    "                precision, recall, f1_score = precision_recall_f1(pred_mask, true_mask)\n",
    "                \n",
    "                dice_scores.append(dice_score)\n",
    "                iou_scores.append(iou_score)\n",
    "                precision_scores.append(precision)\n",
    "                recall_scores.append(recall)\n",
    "                f1_scores.append(f1_score)\n",
    "                \n",
    "                if (actual_idx + 1) % 50 == 0:\n",
    "                    print(f\"Processed {actual_idx + 1}/{num_samples} samples. \"\n",
    "                          f\"Current avg Dice: {np.mean(dice_scores):.4f}\")\n",
    "                \n",
    "                if save_visualizations and (actual_idx < 10 or actual_idx % 100 == 0):\n",
    "                    save_evaluation_visualization(\n",
    "                        sample[\"image\"], pred_mask, true_mask, \n",
    "                        sample[\"point_coords\"], actual_idx,\n",
    "                        dice_score, iou_score, f1_score,\n",
    "                        visualization_dir\n",
    "                    )\n",
    "                \n",
    "        except torch.cuda.OutOfMemoryError:\n",
    "            print(f\"CUDA OOM error at batch starting with sample {i}. Skipping batch...\")\n",
    "            torch.cuda.empty_cache()\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing batch starting with sample {i}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        if i % (batch_size * 10) == 0:\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    results = {\n",
    "        'dice_mean': np.mean(dice_scores),\n",
    "        'dice_std': np.std(dice_scores),\n",
    "        'dice_median': np.median(dice_scores),\n",
    "        'iou_mean': np.mean(iou_scores),\n",
    "        'iou_std': np.std(iou_scores),\n",
    "        'iou_median': np.median(iou_scores),\n",
    "        'precision_mean': np.mean(precision_scores),\n",
    "        'precision_std': np.std(precision_scores),\n",
    "        'recall_mean': np.mean(recall_scores),\n",
    "        'recall_std': np.std(recall_scores),\n",
    "        'f1_mean': np.mean(f1_scores),\n",
    "        'f1_std': np.std(f1_scores),\n",
    "        'num_samples': len(dice_scores),\n",
    "        'dice_scores': dice_scores,\n",
    "        'iou_scores': iou_scores,\n",
    "        'precision_scores': precision_scores,\n",
    "        'recall_scores': recall_scores,\n",
    "        'f1_scores': f1_scores\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "def save_evaluation_visualization(image_tensor, pred_mask, true_mask, coords, \n",
    "                                sample_idx, dice_score, iou_score, f1_score, save_dir):\n",
    "\n",
    "    image = image_tensor.permute(1, 2, 0).numpy()\n",
    "    \n",
    "    pred_binary = (pred_mask > 0.5).astype(np.float32)\n",
    "    true_binary = (true_mask > 0.5).astype(np.float32)\n",
    "    \n",
    "    plt.figure(figsize=(20, 5))\n",
    "    \n",
    "    plt.subplot(1, 5, 1)\n",
    "    plt.imshow(image)\n",
    "    plt.scatter(coords[0][0], coords[0][1], c='red', s=100, marker='*', \n",
    "                edgecolors='white', linewidth=2)\n",
    "    plt.title(\"Original Image + Point\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 5, 2)\n",
    "    plt.imshow(pred_binary, cmap=\"gray\")\n",
    "    plt.title(f\"Predicted Mask\\n{np.sum(pred_binary)} pixels\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 5, 3)\n",
    "    plt.imshow(true_binary, cmap=\"gray\")\n",
    "    plt.title(f\"Ground Truth Mask\\n{np.sum(true_binary)} pixels\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 5, 4)\n",
    "    plt.imshow(image)\n",
    "    overlay = np.zeros((*pred_binary.shape, 4))\n",
    "    overlay[pred_binary > 0.5] = [1, 0, 0, 0.6]  \n",
    "    overlay[true_binary > 0.5] = [0, 1, 0, 0.6] \n",
    "    overlap = (pred_binary > 0.5) & (true_binary > 0.5)\n",
    "    overlay[overlap] = [1, 1, 0, 0.6] \n",
    "    plt.imshow(overlay)\n",
    "    plt.scatter(coords[0][0], coords[0][1], c='white', s=100, marker='*', \n",
    "                edgecolors='black', linewidth=2)\n",
    "    plt.title(\"Overlay\\n(Red: Pred, Green: GT, Yellow: Overlap)\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 5, 5)\n",
    "    diff = pred_binary - true_binary\n",
    "    plt.imshow(diff, cmap=\"RdBu\", vmin=-1, vmax=1)\n",
    "    plt.colorbar(shrink=0.6)\n",
    "    plt.title(\"Difference\\n(Blue: FN, Red: FP)\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.suptitle(f\"Sample {sample_idx} - Dice: {dice_score:.3f}, IoU: {iou_score:.3f}, F1: {f1_score:.3f}\", \n",
    "                 fontsize=14, y=1.02)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{save_dir}/evaluation_sample_{sample_idx:04d}.png\", \n",
    "                dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def print_evaluation_results(results):\n",
    "    \"\"\"\n",
    "    Print comprehensive evaluation results.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"SAM MODEL EVALUATION RESULTS\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Number of samples evaluated: {results['num_samples']}\")\n",
    "    print()\n",
    "    \n",
    "    print(\"DICE SIMILARITY COEFFICIENT:\")\n",
    "    print(f\"  Mean:   {results['dice_mean']:.4f} ± {results['dice_std']:.4f}\")\n",
    "    print(f\"  Median: {results['dice_median']:.4f}\")\n",
    "    print(f\"  Min:    {np.min(results['dice_scores']):.4f}\")\n",
    "    print(f\"  Max:    {np.max(results['dice_scores']):.4f}\")\n",
    "    print()\n",
    "    \n",
    "    print(\"INTERSECTION OVER UNION (IoU):\")\n",
    "    print(f\"  Mean:   {results['iou_mean']:.4f} ± {results['iou_std']:.4f}\")\n",
    "    print(f\"  Median: {results['iou_median']:.4f}\")\n",
    "    print(f\"  Min:    {np.min(results['iou_scores']):.4f}\")\n",
    "    print(f\"  Max:    {np.max(results['iou_scores']):.4f}\")\n",
    "    print()\n",
    "    \n",
    "    print(\"PRECISION:\")\n",
    "    print(f\"  Mean:   {results['precision_mean']:.4f} ± {results['precision_std']:.4f}\")\n",
    "    print()\n",
    "    \n",
    "    print(\"RECALL:\")\n",
    "    print(f\"  Mean:   {results['recall_mean']:.4f} ± {results['recall_std']:.4f}\")\n",
    "    print()\n",
    "    \n",
    "    print(\"F1-SCORE:\")\n",
    "    print(f\"  Mean:   {results['f1_mean']:.4f} ± {results['f1_std']:.4f}\")\n",
    "    print()\n",
    "    \n",
    "    # Performance categories\n",
    "    excellent_dice = np.sum(np.array(results['dice_scores']) >= 0.9)\n",
    "    good_dice = np.sum((np.array(results['dice_scores']) >= 0.7) & \n",
    "                      (np.array(results['dice_scores']) < 0.9))\n",
    "    poor_dice = np.sum(np.array(results['dice_scores']) < 0.5)\n",
    "    \n",
    "    print(\"PERFORMANCE DISTRIBUTION (Dice Score):\")\n",
    "    print(f\"  Excellent (≥0.9): {excellent_dice} samples ({excellent_dice/results['num_samples']*100:.1f}%)\")\n",
    "    print(f\"  Good (0.7-0.9):   {good_dice} samples ({good_dice/results['num_samples']*100:.1f}%)\")\n",
    "    print(f\"  Poor (<0.5):      {poor_dice} samples ({poor_dice/results['num_samples']*100:.1f}%)\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "def plot_evaluation_metrics(results, save_path=None):\n",
    "    \"\"\"\n",
    "    Plot histograms of evaluation metrics.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    \n",
    "    # Dice scores\n",
    "    axes[0, 0].hist(results['dice_scores'], bins=30, alpha=0.7, color='blue', edgecolor='black')\n",
    "    axes[0, 0].axvline(results['dice_mean'], color='red', linestyle='--', \n",
    "                       label=f'Mean: {results[\"dice_mean\"]:.3f}')\n",
    "    axes[0, 0].set_title('Dice Similarity Coefficient')\n",
    "    axes[0, 0].set_xlabel('Dice Score')\n",
    "    axes[0, 0].set_ylabel('Frequency')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # IoU scores\n",
    "    axes[0, 1].hist(results['iou_scores'], bins=30, alpha=0.7, color='green', edgecolor='black')\n",
    "    axes[0, 1].axvline(results['iou_mean'], color='red', linestyle='--', \n",
    "                       label=f'Mean: {results[\"iou_mean\"]:.3f}')\n",
    "    axes[0, 1].set_title('Intersection over Union (IoU)')\n",
    "    axes[0, 1].set_xlabel('IoU Score')\n",
    "    axes[0, 1].set_ylabel('Frequency')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # F1 scores\n",
    "    axes[0, 2].hist(results['f1_scores'], bins=30, alpha=0.7, color='purple', edgecolor='black')\n",
    "    axes[0, 2].axvline(results['f1_mean'], color='red', linestyle='--', \n",
    "                       label=f'Mean: {results[\"f1_mean\"]:.3f}')\n",
    "    axes[0, 2].set_title('F1-Score')\n",
    "    axes[0, 2].set_xlabel('F1 Score')\n",
    "    axes[0, 2].set_ylabel('Frequency')\n",
    "    axes[0, 2].legend()\n",
    "    axes[0, 2].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Precision\n",
    "    axes[1, 0].hist(results['precision_scores'], bins=30, alpha=0.7, color='orange', edgecolor='black')\n",
    "    axes[1, 0].axvline(results['precision_mean'], color='red', linestyle='--', \n",
    "                       label=f'Mean: {results[\"precision_mean\"]:.3f}')\n",
    "    axes[1, 0].set_title('Precision')\n",
    "    axes[1, 0].set_xlabel('Precision')\n",
    "    axes[1, 0].set_ylabel('Frequency')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Recall\n",
    "    axes[1, 1].hist(results['recall_scores'], bins=30, alpha=0.7, color='brown', edgecolor='black')\n",
    "    axes[1, 1].axvline(results['recall_mean'], color='red', linestyle='--', \n",
    "                       label=f'Mean: {results[\"recall_mean\"]:.3f}')\n",
    "    axes[1, 1].set_title('Recall')\n",
    "    axes[1, 1].set_xlabel('Recall')\n",
    "    axes[1, 1].set_ylabel('Frequency')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Scatter plot: Dice vs IoU\n",
    "    axes[1, 2].scatter(results['dice_scores'], results['iou_scores'], alpha=0.6, color='teal')\n",
    "    axes[1, 2].set_title('Dice vs IoU Correlation')\n",
    "    axes[1, 2].set_xlabel('Dice Score')\n",
    "    axes[1, 2].set_ylabel('IoU Score')\n",
    "    axes[1, 2].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Calculate correlation\n",
    "    correlation = np.corrcoef(results['dice_scores'], results['iou_scores'])[0, 1]\n",
    "    axes[1, 2].text(0.05, 0.95, f'Correlation: {correlation:.3f}', \n",
    "                    transform=axes[1, 2].transAxes, verticalalignment='top',\n",
    "                    bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Metrics plot saved to {save_path}\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e2e00a-6f4a-4e60-844e-4d857d5dda53",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_results = evaluate_cardiac_parameters(\n",
    "    test_dataset, model, processor, device, num_samples=len(test_dataset)  \n",
    ")\n",
    "    \n",
    "print_evaluation_results(evaluation_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee2fee0-6e8c-47a1-9a2d-0cc647360da9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d13ce2-1670-46b5-bbad-a14e2a61aea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After training, evaluate your model\n",
    "results = evaluate_sam_model(\n",
    "    model=model,\n",
    "    processor=processor, \n",
    "    dataset=test_dataset,  # or test_dataset\n",
    "    device=device,\n",
    "    num_samples=None,  # None for all samples, or specify a number\n",
    "    batch_size=1,\n",
    "    save_visualizations=True\n",
    ")\n",
    "\n",
    "# Print detailed results\n",
    "print_evaluation_results(results)\n",
    "\n",
    "# Plot metrics histograms\n",
    "plot_evaluation_metrics(results, save_path=\"./evaluation_metrics.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
